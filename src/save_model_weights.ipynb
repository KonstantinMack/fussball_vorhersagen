{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper_fcts import preprocess, get_poi_mas, rps\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "from IPython.display import SVG, HTML\n",
    "from operator import itemgetter\n",
    "from scipy.stats import poisson\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from main import modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:493: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return mu >= 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([modelling(pd.read_csv(\"data/D\" + str(i) + \".csv\"), 18) for i in range(8,19)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mit_fe  = ['FTR', 'season', 'H_avgGD', 'A_avgGD', 'H_avgG', 'A_avgG', 'H_avgG_c', 'A_avgG_c', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4','H_Def_Rat', 'H_Off_Rat', 'A_Def_Rat', 'A_Off_Rat', \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\"]\n",
    "data2 = df[df[\"round\"] > 10].reset_index(drop=True)\n",
    "data = data2.loc[:,columns_mit_fe]\n",
    "data.dropna(inplace=True)\n",
    "X_train = data[data[\"season\"]<18].iloc[:,2:]\n",
    "X_test = data[data[\"season\"]==18].iloc[:,2:]\n",
    "y_train = data[data[\"season\"]<18].loc[:,\"FTR\"]\n",
    "y_test = data[data[\"season\"]==18].loc[:,\"FTR\"]\n",
    "\n",
    "X = data.iloc[:,2:]\n",
    "y = data.loc[:,\"FTR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50,max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training data: seasons 2008 - 2017\n",
    "- test data: season 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rdf_clf_eng3.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'rdf_clf_eng3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=50, max_depth=4)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_clf_eng3.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'xgb_clf_eng3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_mit_fe  = ['Home', 'Draw', 'Away', 'season', 'H_avgGD', 'A_avgGD', 'H_avgG', 'A_avgG', 'H_avgG_c', 'A_avgG_c', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4','H_Def_Rat', 'H_Off_Rat', 'A_Def_Rat', 'A_Off_Rat', \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\"]\n",
    "\n",
    "def get_season(df, season):\n",
    "    X_train = df[df[\"season\"] < season].iloc[:,4:]\n",
    "    X_test = df[df[\"season\"] == season].iloc[:,4:]\n",
    "    y_train = df[df[\"season\"] < season].iloc[:,:3]\n",
    "    y_test = df[df[\"season\"] == season].iloc[:,:3]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "data2 = df[df[\"round\"] > 10].reset_index(drop=True)\n",
    "data = data2[columns_mit_fe]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X = data.iloc[:,4:]\n",
    "y = data.iloc[:,:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "#joblib.dump(scaler, 'scaler_eng3.joblib')\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rps(y_true, y_pred):\n",
    "    prob_h = y_pred[:, 0]\n",
    "    prob_d = y_pred[:, 1]\n",
    "    home = y_true[:, 0]\n",
    "    draw = y_true[:, 1]\n",
    "\n",
    "    step1 = prob_h - home\n",
    "    step2 = prob_d - draw\n",
    "    summe = step1 + step2\n",
    "    return (step1 ** 2 + summe ** 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, kernel_initializer=\"he_normal\", input_shape=(23,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=loss_rps, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2376/2376 [==============================] - 1s 226us/step - loss: 0.3129 - acc: 0.3834\n",
      "Epoch 2/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2976 - acc: 0.3986\n",
      "Epoch 3/100\n",
      "2376/2376 [==============================] - 0s 77us/step - loss: 0.2813 - acc: 0.3990\n",
      "Epoch 4/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2712 - acc: 0.4091\n",
      "Epoch 5/100\n",
      "2376/2376 [==============================] - 0s 68us/step - loss: 0.2693 - acc: 0.4171\n",
      "Epoch 6/100\n",
      "2376/2376 [==============================] - 0s 70us/step - loss: 0.2567 - acc: 0.4217\n",
      "Epoch 7/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.2487 - acc: 0.4213\n",
      "Epoch 8/100\n",
      "2376/2376 [==============================] - 0s 84us/step - loss: 0.2426 - acc: 0.4141\n",
      "Epoch 9/100\n",
      "2376/2376 [==============================] - 0s 92us/step - loss: 0.2326 - acc: 0.4238\n",
      "Epoch 10/100\n",
      "2376/2376 [==============================] - 0s 89us/step - loss: 0.2308 - acc: 0.4364\n",
      "Epoch 11/100\n",
      "2376/2376 [==============================] - 0s 98us/step - loss: 0.2275 - acc: 0.4482\n",
      "Epoch 12/100\n",
      "2376/2376 [==============================] - 0s 71us/step - loss: 0.2210 - acc: 0.4465\n",
      "Epoch 13/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2204 - acc: 0.4600\n",
      "Epoch 14/100\n",
      "2376/2376 [==============================] - 0s 79us/step - loss: 0.2203 - acc: 0.4617\n",
      "Epoch 15/100\n",
      "2376/2376 [==============================] - 0s 72us/step - loss: 0.2152 - acc: 0.4726\n",
      "Epoch 16/100\n",
      "2376/2376 [==============================] - 0s 82us/step - loss: 0.2163 - acc: 0.4714\n",
      "Epoch 17/100\n",
      "2376/2376 [==============================] - 0s 70us/step - loss: 0.2174 - acc: 0.4731\n",
      "Epoch 18/100\n",
      "2376/2376 [==============================] - 0s 74us/step - loss: 0.2106 - acc: 0.5055\n",
      "Epoch 19/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2137 - acc: 0.4916\n",
      "Epoch 20/100\n",
      "2376/2376 [==============================] - 0s 73us/step - loss: 0.2108 - acc: 0.4992\n",
      "Epoch 21/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.2122 - acc: 0.4907\n",
      "Epoch 22/100\n",
      "2376/2376 [==============================] - 0s 71us/step - loss: 0.2110 - acc: 0.5042\n",
      "Epoch 23/100\n",
      "2376/2376 [==============================] - 0s 77us/step - loss: 0.2107 - acc: 0.5008\n",
      "Epoch 24/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2119 - acc: 0.4954\n",
      "Epoch 25/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2101 - acc: 0.5072\n",
      "Epoch 26/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2126 - acc: 0.4975\n",
      "Epoch 27/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2080 - acc: 0.5038\n",
      "Epoch 28/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2098 - acc: 0.5038\n",
      "Epoch 29/100\n",
      "2376/2376 [==============================] - 0s 80us/step - loss: 0.2114 - acc: 0.4903\n",
      "Epoch 30/100\n",
      "2376/2376 [==============================] - 0s 71us/step - loss: 0.2105 - acc: 0.5004\n",
      "Epoch 31/100\n",
      "2376/2376 [==============================] - 0s 71us/step - loss: 0.2084 - acc: 0.5034\n",
      "Epoch 32/100\n",
      "2376/2376 [==============================] - 0s 65us/step - loss: 0.2086 - acc: 0.5063\n",
      "Epoch 33/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.2085 - acc: 0.5051\n",
      "Epoch 34/100\n",
      "2376/2376 [==============================] - 0s 98us/step - loss: 0.2088 - acc: 0.5139\n",
      "Epoch 35/100\n",
      "2376/2376 [==============================] - 0s 84us/step - loss: 0.2090 - acc: 0.5059\n",
      "Epoch 36/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.2084 - acc: 0.5051\n",
      "Epoch 37/100\n",
      "2376/2376 [==============================] - 0s 89us/step - loss: 0.2078 - acc: 0.5109\n",
      "Epoch 38/100\n",
      "2376/2376 [==============================] - 0s 92us/step - loss: 0.2084 - acc: 0.5088\n",
      "Epoch 39/100\n",
      "2376/2376 [==============================] - 0s 103us/step - loss: 0.2095 - acc: 0.5000\n",
      "Epoch 40/100\n",
      "2376/2376 [==============================] - 0s 112us/step - loss: 0.2066 - acc: 0.5080\n",
      "Epoch 41/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2078 - acc: 0.5067\n",
      "Epoch 42/100\n",
      "2376/2376 [==============================] - 0s 95us/step - loss: 0.2079 - acc: 0.5114\n",
      "Epoch 43/100\n",
      "2376/2376 [==============================] - 0s 64us/step - loss: 0.2075 - acc: 0.5088\n",
      "Epoch 44/100\n",
      "2376/2376 [==============================] - 0s 60us/step - loss: 0.2077 - acc: 0.5076\n",
      "Epoch 45/100\n",
      "2376/2376 [==============================] - 0s 64us/step - loss: 0.2065 - acc: 0.5067\n",
      "Epoch 46/100\n",
      "2376/2376 [==============================] - 0s 65us/step - loss: 0.2065 - acc: 0.5118\n",
      "Epoch 47/100\n",
      "2376/2376 [==============================] - 0s 64us/step - loss: 0.2064 - acc: 0.5067\n",
      "Epoch 48/100\n",
      "2376/2376 [==============================] - 0s 61us/step - loss: 0.2068 - acc: 0.5063\n",
      "Epoch 49/100\n",
      "2376/2376 [==============================] - 0s 64us/step - loss: 0.2069 - acc: 0.5038\n",
      "Epoch 50/100\n",
      "2376/2376 [==============================] - 0s 59us/step - loss: 0.2075 - acc: 0.5114\n",
      "Epoch 51/100\n",
      "2376/2376 [==============================] - 0s 63us/step - loss: 0.2053 - acc: 0.5135\n",
      "Epoch 52/100\n",
      "2376/2376 [==============================] - 0s 92us/step - loss: 0.2057 - acc: 0.5135\n",
      "Epoch 53/100\n",
      "2376/2376 [==============================] - 0s 86us/step - loss: 0.2043 - acc: 0.5269\n",
      "Epoch 54/100\n",
      "2376/2376 [==============================] - 0s 63us/step - loss: 0.2075 - acc: 0.5097\n",
      "Epoch 55/100\n",
      "2376/2376 [==============================] - 0s 56us/step - loss: 0.2060 - acc: 0.5160\n",
      "Epoch 56/100\n",
      "2376/2376 [==============================] - 0s 65us/step - loss: 0.2053 - acc: 0.5080\n",
      "Epoch 57/100\n",
      "2376/2376 [==============================] - 0s 69us/step - loss: 0.2049 - acc: 0.5253\n",
      "Epoch 58/100\n",
      "2376/2376 [==============================] - 0s 61us/step - loss: 0.2045 - acc: 0.5194\n",
      "Epoch 59/100\n",
      "2376/2376 [==============================] - 0s 83us/step - loss: 0.2057 - acc: 0.5067\n",
      "Epoch 60/100\n",
      "2376/2376 [==============================] - 0s 77us/step - loss: 0.2052 - acc: 0.5126\n",
      "Epoch 61/100\n",
      "2376/2376 [==============================] - 0s 72us/step - loss: 0.2059 - acc: 0.5122\n",
      "Epoch 62/100\n",
      "2376/2376 [==============================] - 0s 72us/step - loss: 0.2050 - acc: 0.4996\n",
      "Epoch 63/100\n",
      "2376/2376 [==============================] - 0s 71us/step - loss: 0.2057 - acc: 0.5080\n",
      "Epoch 64/100\n",
      "2376/2376 [==============================] - 0s 83us/step - loss: 0.2044 - acc: 0.5206\n",
      "Epoch 65/100\n",
      "2376/2376 [==============================] - 0s 82us/step - loss: 0.2054 - acc: 0.5101\n",
      "Epoch 66/100\n",
      "2376/2376 [==============================] - 0s 86us/step - loss: 0.2022 - acc: 0.5261\n",
      "Epoch 67/100\n",
      "2376/2376 [==============================] - 0s 83us/step - loss: 0.2045 - acc: 0.5202\n",
      "Epoch 68/100\n",
      "2376/2376 [==============================] - 0s 81us/step - loss: 0.2039 - acc: 0.5122\n",
      "Epoch 69/100\n",
      "2376/2376 [==============================] - 0s 76us/step - loss: 0.2039 - acc: 0.5173\n",
      "Epoch 70/100\n",
      "2376/2376 [==============================] - 0s 96us/step - loss: 0.2048 - acc: 0.5126\n",
      "Epoch 71/100\n",
      "2376/2376 [==============================] - 0s 84us/step - loss: 0.2051 - acc: 0.5109\n",
      "Epoch 72/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2033 - acc: 0.5168\n",
      "Epoch 73/100\n",
      "2376/2376 [==============================] - 0s 81us/step - loss: 0.2060 - acc: 0.5143\n",
      "Epoch 74/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2055 - acc: 0.5198\n",
      "Epoch 75/100\n",
      "2376/2376 [==============================] - 0s 78us/step - loss: 0.2019 - acc: 0.5189\n",
      "Epoch 76/100\n",
      "2376/2376 [==============================] - 0s 74us/step - loss: 0.2060 - acc: 0.5185\n",
      "Epoch 77/100\n",
      "2376/2376 [==============================] - 0s 66us/step - loss: 0.2054 - acc: 0.5046\n",
      "Epoch 78/100\n",
      "2376/2376 [==============================] - 0s 65us/step - loss: 0.2029 - acc: 0.5219\n",
      "Epoch 79/100\n",
      "2376/2376 [==============================] - 0s 56us/step - loss: 0.2030 - acc: 0.5143\n",
      "Epoch 80/100\n",
      "2376/2376 [==============================] - 0s 60us/step - loss: 0.2044 - acc: 0.5194\n",
      "Epoch 81/100\n",
      "2376/2376 [==============================] - 0s 64us/step - loss: 0.2034 - acc: 0.5147\n",
      "Epoch 82/100\n",
      "2376/2376 [==============================] - 0s 66us/step - loss: 0.2020 - acc: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "2376/2376 [==============================] - 0s 59us/step - loss: 0.2031 - acc: 0.5185\n",
      "Epoch 84/100\n",
      "2376/2376 [==============================] - 0s 58us/step - loss: 0.2002 - acc: 0.5223\n",
      "Epoch 85/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.2047 - acc: 0.5147\n",
      "Epoch 86/100\n",
      "2376/2376 [==============================] - 0s 73us/step - loss: 0.2014 - acc: 0.5118\n",
      "Epoch 87/100\n",
      "2376/2376 [==============================] - 0s 60us/step - loss: 0.2028 - acc: 0.5139\n",
      "Epoch 88/100\n",
      "2376/2376 [==============================] - 0s 65us/step - loss: 0.2024 - acc: 0.5168\n",
      "Epoch 89/100\n",
      "2376/2376 [==============================] - 0s 63us/step - loss: 0.2030 - acc: 0.5101\n",
      "Epoch 90/100\n",
      "2376/2376 [==============================] - 0s 63us/step - loss: 0.2007 - acc: 0.5248\n",
      "Epoch 91/100\n",
      "2376/2376 [==============================] - 0s 68us/step - loss: 0.2019 - acc: 0.5126\n",
      "Epoch 92/100\n",
      "2376/2376 [==============================] - 0s 63us/step - loss: 0.2026 - acc: 0.5152\n",
      "Epoch 93/100\n",
      "2376/2376 [==============================] - 0s 75us/step - loss: 0.1999 - acc: 0.5152\n",
      "Epoch 94/100\n",
      "2376/2376 [==============================] - 0s 82us/step - loss: 0.2048 - acc: 0.5147\n",
      "Epoch 95/100\n",
      "2376/2376 [==============================] - 0s 85us/step - loss: 0.1988 - acc: 0.5248\n",
      "Epoch 96/100\n",
      "2376/2376 [==============================] - 0s 108us/step - loss: 0.2010 - acc: 0.5231\n",
      "Epoch 97/100\n",
      "2376/2376 [==============================] - 0s 89us/step - loss: 0.2015 - acc: 0.5206\n",
      "Epoch 98/100\n",
      "2376/2376 [==============================] - 0s 84us/step - loss: 0.2001 - acc: 0.5286\n",
      "Epoch 99/100\n",
      "2376/2376 [==============================] - 0s 111us/step - loss: 0.2016 - acc: 0.5152\n",
      "Epoch 100/100\n",
      "2376/2376 [==============================] - 0s 94us/step - loss: 0.2000 - acc: 0.5240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b978749630>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ann_clf_ger.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicting Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_mit_fe  = ['FTHG', 'FTAG', 'season', 'H_avgGD', 'A_avgGD', 'H_avgG', 'A_avgG', 'H_avgG_c', 'A_avgG_c', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4','H_Def_Rat', 'H_Off_Rat', 'A_Def_Rat', 'A_Off_Rat', \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\"]\n",
    "def get_season(df, season):\n",
    "    X_train = df[df[\"season\"] < season].iloc[:,2:]\n",
    "    X_test = df[df[\"season\"] == season].iloc[:,2:]\n",
    "    y_train_hg = df[df[\"season\"] < season].iloc[:,0]\n",
    "    y_test_hg = df[df[\"season\"] == season].iloc[:,0]\n",
    "    y_train_ag = df[df[\"season\"] < season].iloc[:,1]\n",
    "    y_test_ag = df[df[\"season\"] == season].iloc[:,1]\n",
    "    return X_train, X_test, y_train_hg, y_test_hg, y_train_ag, y_test_ag\n",
    "\n",
    "data2 = df[df[\"round\"] > 10].reset_index(drop=True)\n",
    "data = data2[columns_mit_fe]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X = data.iloc[:,3:]\n",
    "y_h = data.iloc[:,0]\n",
    "y_a = data.iloc[:,1]\n",
    "\n",
    "# X_train, X_test, y_train_hg, y_test_hg, y_train_ag, y_test_ag = get_season(data, 18)\n",
    "\n",
    "# del X_train[\"season\"]\n",
    "# del X_test[\"season\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#home\n",
    "model_h = XGBRegressor(n_estimators=50, max_depth=4)\n",
    "model_h.fit(X, y_h)\n",
    "#xgb_home = model_h.predict(X_test)\n",
    "\n",
    "#away\n",
    "model_a = XGBRegressor(n_estimators=50, max_depth=4)\n",
    "model_a.fit(X, y_a)\n",
    "#xgb_away = model_a.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_reg_eng3_a.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_h, 'xgb_reg_eng3_h.joblib')\n",
    "joblib.dump(model_a, 'xgb_reg_eng3_a.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#columns_mit_fe  = ['FTHG', 'FTAG', 'season', 'H_avgGD', 'A_avgGD', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4', 'H_prob_odds', 'D_prob_odds', 'A_prob_odds']\n",
    "columns_mit_fe  = ['FTHG', 'FTAG', 'season', 'H_avgGD', 'A_avgGD', 'H_avgG', 'A_avgG', 'H_avgG_c', 'A_avgG_c', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4','H_Def_Rat', 'H_Off_Rat', 'A_Def_Rat', 'A_Off_Rat', \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\"]\n",
    "\n",
    "def get_season(df, season):\n",
    "    X_train = df[df[\"season\"] < season].iloc[:,2:]\n",
    "    X_test = df[df[\"season\"] == season].iloc[:,2:]\n",
    "    y_train_hg = df[df[\"season\"] < season].iloc[:,0]\n",
    "    y_test_hg = df[df[\"season\"] == season].iloc[:,0]\n",
    "    y_train_ag = df[df[\"season\"] < season].iloc[:,1]\n",
    "    y_test_ag = df[df[\"season\"] == season].iloc[:,1]\n",
    "    return X_train, X_test, y_train_hg, y_test_hg, y_train_ag, y_test_ag\n",
    "\n",
    "data2 = df[df[\"round\"] > 10].reset_index(drop=True)\n",
    "data = data2[columns_mit_fe]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X_train, X_test, y_train_hg, y_test_hg, y_train_ag, y_test_ag = get_season(data, 18)\n",
    "\n",
    "X = data.iloc[:,3:]\n",
    "y_h = data.iloc[:,0]\n",
    "y_a = data.iloc[:,1]\n",
    "\n",
    "# del X_train[\"season\"]\n",
    "# del X_test[\"season\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#home\n",
    "model_h = SVR()\n",
    "model_h.fit(X, y_h)\n",
    "#svr_home = model_h.predict(X_test)\n",
    "\n",
    "#away\n",
    "model_a = SVR()\n",
    "model_a.fit(X, y_a)\n",
    "#svr_away = model_a.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svr_reg_eng3_a.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_h, 'svr_reg_eng3_h.joblib')\n",
    "joblib.dump(model_a, 'svr_reg_eng3_a.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_mit_fe  = ['FTHG', 'FTAG', 'season', 'H_avgGD', 'A_avgGD', 'H_avgG', 'A_avgG', 'H_avgG_c', 'A_avgG_c', 'H_avgST', 'A_avgST', 'H_avgST_c', 'A_avgST_c', 'H_GoalDiff_last', 'A_GoalDiff_last', 'H_xG_PoiMas', 'A_xG_PoiMas', 'H_Form_Tot4', 'A_Form_Tot4','H_Def_Rat', 'H_Off_Rat', 'A_Def_Rat', 'A_Off_Rat', \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\"]\n",
    "\n",
    "def get_season(df, season):\n",
    "    X_train = df[df[\"season\"] < season].iloc[:,3:]\n",
    "    X_test = df[df[\"season\"] == season].iloc[:,3:]\n",
    "    y_train = df[df[\"season\"] < season].iloc[:,:2]\n",
    "    y_test = df[df[\"season\"] == season].iloc[:,:2]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "data2 = df[df[\"round\"] > 10].reset_index(drop=True)\n",
    "data = data2[columns_mit_fe]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = get_season(data, 18)\n",
    "\n",
    "X = data.iloc[:,3:]\n",
    "y = data.iloc[:,:2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, kernel_initializer=\"he_normal\", input_shape=(23,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss=\"logcosh\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4752/4752 [==============================] - 1s 110us/step - loss: 0.9148 - acc: 0.5305\n",
      "Epoch 2/80\n",
      "4752/4752 [==============================] - 0s 60us/step - loss: 0.6379 - acc: 0.5513\n",
      "Epoch 3/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.5560 - acc: 0.5852\n",
      "Epoch 4/80\n",
      "4752/4752 [==============================] - 0s 59us/step - loss: 0.5183 - acc: 0.6061\n",
      "Epoch 5/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4897 - acc: 0.6349\n",
      "Epoch 6/80\n",
      "4752/4752 [==============================] - 0s 60us/step - loss: 0.4809 - acc: 0.6374\n",
      "Epoch 7/80\n",
      "4752/4752 [==============================] - 0s 60us/step - loss: 0.4728 - acc: 0.6524\n",
      "Epoch 8/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4629 - acc: 0.6481\n",
      "Epoch 9/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4588 - acc: 0.6503\n",
      "Epoch 10/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4602 - acc: 0.6515\n",
      "Epoch 11/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4536 - acc: 0.6511\n",
      "Epoch 12/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4512 - acc: 0.6644\n",
      "Epoch 13/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4524 - acc: 0.6473\n",
      "Epoch 14/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4500 - acc: 0.6532\n",
      "Epoch 15/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4481 - acc: 0.6660\n",
      "Epoch 16/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4459 - acc: 0.6578\n",
      "Epoch 17/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4454 - acc: 0.6564\n",
      "Epoch 18/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4446 - acc: 0.6538\n",
      "Epoch 19/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4436 - acc: 0.6631\n",
      "Epoch 20/80\n",
      "4752/4752 [==============================] - 0s 71us/step - loss: 0.4441 - acc: 0.6559\n",
      "Epoch 21/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4431 - acc: 0.6627\n",
      "Epoch 22/80\n",
      "4752/4752 [==============================] - 0s 60us/step - loss: 0.4438 - acc: 0.6597\n",
      "Epoch 23/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4431 - acc: 0.6646\n",
      "Epoch 24/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4433 - acc: 0.6641\n",
      "Epoch 25/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4421 - acc: 0.6595\n",
      "Epoch 26/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4409 - acc: 0.6675\n",
      "Epoch 27/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4417 - acc: 0.6654\n",
      "Epoch 28/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4406 - acc: 0.6606\n",
      "Epoch 29/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4385 - acc: 0.6610\n",
      "Epoch 30/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4411 - acc: 0.6669\n",
      "Epoch 31/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4394 - acc: 0.6715\n",
      "Epoch 32/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4405 - acc: 0.6656\n",
      "Epoch 33/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4379 - acc: 0.6654\n",
      "Epoch 34/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4393 - acc: 0.6665\n",
      "Epoch 35/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4401 - acc: 0.6606\n",
      "Epoch 36/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4397 - acc: 0.6652\n",
      "Epoch 37/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4390 - acc: 0.6656\n",
      "Epoch 38/80\n",
      "4752/4752 [==============================] - 0s 70us/step - loss: 0.4390 - acc: 0.6713\n",
      "Epoch 39/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4377 - acc: 0.6719\n",
      "Epoch 40/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4381 - acc: 0.6715\n",
      "Epoch 41/80\n",
      "4752/4752 [==============================] - 0s 61us/step - loss: 0.4386 - acc: 0.6742\n",
      "Epoch 42/80\n",
      "4752/4752 [==============================] - 0s 74us/step - loss: 0.4374 - acc: 0.6732\n",
      "Epoch 43/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4367 - acc: 0.6713\n",
      "Epoch 44/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4371 - acc: 0.6705\n",
      "Epoch 45/80\n",
      "4752/4752 [==============================] - 0s 74us/step - loss: 0.4378 - acc: 0.6742\n",
      "Epoch 46/80\n",
      "4752/4752 [==============================] - 0s 82us/step - loss: 0.4379 - acc: 0.6707\n",
      "Epoch 47/80\n",
      "4752/4752 [==============================] - 0s 71us/step - loss: 0.4382 - acc: 0.6595\n",
      "Epoch 48/80\n",
      "4752/4752 [==============================] - 0s 69us/step - loss: 0.4387 - acc: 0.6738\n",
      "Epoch 49/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4363 - acc: 0.6723\n",
      "Epoch 50/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4374 - acc: 0.6719\n",
      "Epoch 51/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4368 - acc: 0.6705\n",
      "Epoch 52/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4360 - acc: 0.6679\n",
      "Epoch 53/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4363 - acc: 0.6787\n",
      "Epoch 54/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4368 - acc: 0.6713\n",
      "Epoch 55/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4352 - acc: 0.6749\n",
      "Epoch 56/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4355 - acc: 0.6711\n",
      "Epoch 57/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4360 - acc: 0.6753\n",
      "Epoch 58/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4370 - acc: 0.6728\n",
      "Epoch 59/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4370 - acc: 0.6780\n",
      "Epoch 60/80\n",
      "4752/4752 [==============================] - 0s 60us/step - loss: 0.4363 - acc: 0.6778\n",
      "Epoch 61/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4347 - acc: 0.6700\n",
      "Epoch 62/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4367 - acc: 0.6707\n",
      "Epoch 63/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4367 - acc: 0.6686\n",
      "Epoch 64/80\n",
      "4752/4752 [==============================] - 0s 62us/step - loss: 0.4346 - acc: 0.6717\n",
      "Epoch 65/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4356 - acc: 0.6749\n",
      "Epoch 66/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4355 - acc: 0.6641\n",
      "Epoch 67/80\n",
      "4752/4752 [==============================] - 0s 67us/step - loss: 0.4367 - acc: 0.6740\n",
      "Epoch 68/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4351 - acc: 0.6686\n",
      "Epoch 69/80\n",
      "4752/4752 [==============================] - 0s 63us/step - loss: 0.4364 - acc: 0.6700\n",
      "Epoch 70/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4342 - acc: 0.6732\n",
      "Epoch 71/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4341 - acc: 0.6747\n",
      "Epoch 72/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4335 - acc: 0.6700\n",
      "Epoch 73/80\n",
      "4752/4752 [==============================] - 0s 67us/step - loss: 0.4343 - acc: 0.6721\n",
      "Epoch 74/80\n",
      "4752/4752 [==============================] - 0s 69us/step - loss: 0.4337 - acc: 0.6736\n",
      "Epoch 75/80\n",
      "4752/4752 [==============================] - 0s 65us/step - loss: 0.4361 - acc: 0.6677\n",
      "Epoch 76/80\n",
      "4752/4752 [==============================] - 0s 69us/step - loss: 0.4353 - acc: 0.6745\n",
      "Epoch 77/80\n",
      "4752/4752 [==============================] - 0s 66us/step - loss: 0.4343 - acc: 0.6717\n",
      "Epoch 78/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4344 - acc: 0.6738\n",
      "Epoch 79/80\n",
      "4752/4752 [==============================] - 0s 64us/step - loss: 0.4333 - acc: 0.6816\n",
      "Epoch 80/80\n",
      "4752/4752 [==============================] - 0s 74us/step - loss: 0.4338 - acc: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b96f530e80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACHTUNG ÄNDERN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ann_reg_eng3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from prediction import get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:493: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return mu >= 0\n"
     ]
    }
   ],
   "source": [
    "eng2 = get_predictions(\"eng2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>H_prob_odds</th>\n",
       "      <th>D_prob_odds</th>\n",
       "      <th>A_prob_odds</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>Hc_avg</th>\n",
       "      <th>Hc_Diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Reading</td>\n",
       "      <td>0.542915</td>\n",
       "      <td>0.263186</td>\n",
       "      <td>0.193898</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.937698</td>\n",
       "      <td>-0.062302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Rotherham</td>\n",
       "      <td>0.673659</td>\n",
       "      <td>0.213932</td>\n",
       "      <td>0.112409</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.413674</td>\n",
       "      <td>0.413674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Millwall</td>\n",
       "      <td>Wigan</td>\n",
       "      <td>0.437446</td>\n",
       "      <td>0.283361</td>\n",
       "      <td>0.279193</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-0.224148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norwich</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>0.420456</td>\n",
       "      <td>0.285355</td>\n",
       "      <td>0.294189</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.360187</td>\n",
       "      <td>0.110187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QPR</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.467184</td>\n",
       "      <td>0.280587</td>\n",
       "      <td>0.252230</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.538725</td>\n",
       "      <td>0.288725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0.486190</td>\n",
       "      <td>0.275602</td>\n",
       "      <td>0.238209</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.611639</td>\n",
       "      <td>-0.138361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Swansea</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>0.423749</td>\n",
       "      <td>0.292061</td>\n",
       "      <td>0.284191</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.158933</td>\n",
       "      <td>-0.091067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bolton</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>0.274530</td>\n",
       "      <td>0.296905</td>\n",
       "      <td>0.428565</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.503948</td>\n",
       "      <td>-0.253948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bristol City</td>\n",
       "      <td>Hull</td>\n",
       "      <td>0.512729</td>\n",
       "      <td>0.268711</td>\n",
       "      <td>0.218560</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.720944</td>\n",
       "      <td>-0.029056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>0.667106</td>\n",
       "      <td>0.210978</td>\n",
       "      <td>0.121916</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.486125</td>\n",
       "      <td>0.486125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Preston</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>0.330295</td>\n",
       "      <td>0.277991</td>\n",
       "      <td>0.391714</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.568184</td>\n",
       "      <td>-0.318184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>West Brom</td>\n",
       "      <td>Derby</td>\n",
       "      <td>0.481488</td>\n",
       "      <td>0.264215</td>\n",
       "      <td>0.254298</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.491515</td>\n",
       "      <td>0.241515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomeTeam        AwayTeam  H_prob_odds  D_prob_odds  A_prob_odds  \\\n",
       "0         Birmingham         Reading     0.542915     0.263186     0.193898   \n",
       "1      Middlesbrough       Rotherham     0.673659     0.213932     0.112409   \n",
       "2           Millwall           Wigan     0.437446     0.283361     0.279193   \n",
       "3            Norwich     Aston Villa     0.420456     0.285355     0.294189   \n",
       "4                QPR  Sheffield Weds     0.467184     0.280587     0.252230   \n",
       "5   Sheffield United           Stoke     0.486190     0.275602     0.238209   \n",
       "6            Swansea       Blackburn     0.423749     0.292061     0.284191   \n",
       "7             Bolton   Nott'm Forest     0.274530     0.296905     0.428565   \n",
       "8       Bristol City            Hull     0.512729     0.268711     0.218560   \n",
       "9              Leeds         Ipswich     0.667106     0.210978     0.121916   \n",
       "10           Preston       Brentford     0.330295     0.277991     0.391714   \n",
       "11         West Brom           Derby     0.481488     0.264215     0.254298   \n",
       "\n",
       "    BbAHh    Hc_avg  Hc_Diff_avg  \n",
       "0   -1.00 -0.937698    -0.062302  \n",
       "1   -1.00 -1.413674     0.413674  \n",
       "2   -0.25 -0.025852    -0.224148  \n",
       "3   -0.25 -0.360187     0.110187  \n",
       "4   -0.25 -0.538725     0.288725  \n",
       "5   -0.75 -0.611639    -0.138361  \n",
       "6   -0.25 -0.158933    -0.091067  \n",
       "7    0.25  0.503948    -0.253948  \n",
       "8   -0.75 -0.720944    -0.029056  \n",
       "9   -1.00 -1.486125     0.486125  \n",
       "10   0.25  0.568184    -0.318184  \n",
       "11  -0.25 -0.491515     0.241515  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng2[[\"HomeTeam\", \"AwayTeam\", \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\", \"BbAHh\", \"Hc_avg\", \"Hc_Diff_avg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konny\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_discrete_distns.py:493: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return mu >= 0\n"
     ]
    }
   ],
   "source": [
    "eng3 = get_predictions(\"eng3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>H_prob_odds</th>\n",
       "      <th>D_prob_odds</th>\n",
       "      <th>A_prob_odds</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>Hc_avg</th>\n",
       "      <th>Hc_Diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackpool</td>\n",
       "      <td>Scunthorpe</td>\n",
       "      <td>0.500478</td>\n",
       "      <td>0.264297</td>\n",
       "      <td>0.235225</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.967130</td>\n",
       "      <td>0.217130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bradford</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>0.294305</td>\n",
       "      <td>0.287127</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.081580</td>\n",
       "      <td>0.331580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bristol Rvs</td>\n",
       "      <td>AFC Wimbledon</td>\n",
       "      <td>0.389171</td>\n",
       "      <td>0.291577</td>\n",
       "      <td>0.319252</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.204802</td>\n",
       "      <td>-0.045198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlton</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>0.492996</td>\n",
       "      <td>0.250431</td>\n",
       "      <td>0.256573</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.316180</td>\n",
       "      <td>-0.183820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doncaster</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0.382001</td>\n",
       "      <td>0.284764</td>\n",
       "      <td>0.333235</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.043683</td>\n",
       "      <td>-0.293683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Luton</td>\n",
       "      <td>Accrington</td>\n",
       "      <td>0.575502</td>\n",
       "      <td>0.238339</td>\n",
       "      <td>0.186159</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.111672</td>\n",
       "      <td>0.111672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peterboro</td>\n",
       "      <td>Fleetwood Town</td>\n",
       "      <td>0.450019</td>\n",
       "      <td>0.256978</td>\n",
       "      <td>0.293003</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.236156</td>\n",
       "      <td>-0.013844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plymouth</td>\n",
       "      <td>Gillingham</td>\n",
       "      <td>0.387373</td>\n",
       "      <td>0.275238</td>\n",
       "      <td>0.337389</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.225371</td>\n",
       "      <td>-0.024629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Burton</td>\n",
       "      <td>0.531713</td>\n",
       "      <td>0.268895</td>\n",
       "      <td>0.199392</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.871075</td>\n",
       "      <td>0.121075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>Barnsley</td>\n",
       "      <td>0.277214</td>\n",
       "      <td>0.293674</td>\n",
       "      <td>0.429112</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.304211</td>\n",
       "      <td>-0.054211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Southend</td>\n",
       "      <td>Walsall</td>\n",
       "      <td>0.474238</td>\n",
       "      <td>0.275364</td>\n",
       "      <td>0.250398</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.842277</td>\n",
       "      <td>0.592277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wycombe</td>\n",
       "      <td>Rochdale</td>\n",
       "      <td>0.337281</td>\n",
       "      <td>0.281741</td>\n",
       "      <td>0.380978</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.280182</td>\n",
       "      <td>-0.030182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeTeam        AwayTeam  H_prob_odds  D_prob_odds  A_prob_odds  BbAHh  \\\n",
       "0     Blackpool      Scunthorpe     0.500478     0.264297     0.235225  -0.75   \n",
       "1      Bradford        Coventry     0.294305     0.287127     0.418568   0.25   \n",
       "2   Bristol Rvs   AFC Wimbledon     0.389171     0.291577     0.319252  -0.25   \n",
       "3      Charlton          Oxford     0.492996     0.250431     0.256573  -0.50   \n",
       "4     Doncaster      Sunderland     0.382001     0.284764     0.333235  -0.25   \n",
       "5         Luton      Accrington     0.575502     0.238339     0.186159  -1.00   \n",
       "6     Peterboro  Fleetwood Town     0.450019     0.256978     0.293003  -0.25   \n",
       "7      Plymouth      Gillingham     0.387373     0.275238     0.337389  -0.25   \n",
       "8    Portsmouth          Burton     0.531713     0.268895     0.199392  -0.75   \n",
       "9    Shrewsbury        Barnsley     0.277214     0.293674     0.429112   0.25   \n",
       "10     Southend         Walsall     0.474238     0.275364     0.250398  -0.25   \n",
       "11      Wycombe        Rochdale     0.337281     0.281741     0.380978   0.25   \n",
       "\n",
       "      Hc_avg  Hc_Diff_avg  \n",
       "0  -0.967130     0.217130  \n",
       "1  -0.081580     0.331580  \n",
       "2  -0.204802    -0.045198  \n",
       "3  -0.316180    -0.183820  \n",
       "4   0.043683    -0.293683  \n",
       "5  -1.111672     0.111672  \n",
       "6  -0.236156    -0.013844  \n",
       "7  -0.225371    -0.024629  \n",
       "8  -0.871075     0.121075  \n",
       "9   0.304211    -0.054211  \n",
       "10 -0.842277     0.592277  \n",
       "11  0.280182    -0.030182  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng3[[\"HomeTeam\", \"AwayTeam\", \"H_prob_odds\", \"D_prob_odds\", \"A_prob_odds\", \"BbAHh\", \"Hc_avg\", \"Hc_Diff_avg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HomeTeam', 'AwayTeam', 'H_prob_odds', 'D_prob_odds', 'A_prob_odds',\n",
       "       'BbAHh', 'H_pred_avg', 'D_pred_avg', 'A_pred_avg', 'Hc_avg',\n",
       "       'Hc_Diff_avg', 'H_pred_Rdf', 'H_pred_Xgb', 'H_pred_Ann', 'D_pred_Rdf',\n",
       "       'D_pred_Xgb', 'D_pred_Ann', 'A_pred_Rdf', 'A_pred_Xgb', 'A_pred_Ann',\n",
       "       'XGB_hc', 'SVR_hc', 'ANN_hc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
